{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ba9041-d599-4e59-921c-159086488560",
   "metadata": {},
   "source": [
    "基于深度学习的岩石图像分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb61d30-a1d2-46df-9352-abab6619b61b",
   "metadata": {},
   "source": [
    "图像分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c81e45e-62a8-49f5-b0da-1d54fdb9e1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载训练集...\n",
      "正在加载测试集...\n",
      "数据集加载完成！类别: ['Basalt', 'Clay', 'Conglomerate', 'Diatomite', 'Shale-(Mudstone)', 'Siliceous-sinter', 'chert', 'gypsum', 'olivine-basalt']\n",
      "训练集: 3687张图片, 测试集: 174张图片\n",
      "训练SVM分类器中...\n",
      "模型准确率: 25.86%\n",
      "\n",
      "示例预测: D:/wuyue/Rock_Data/test/Basalt\\0\n",
      "预测结果: 读取图片\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage import exposure\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import warnings #过滤掉python中的FutureWarning\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "# 配置数据集路径\n",
    "train_path = r\"D:/wuyue/Rock_Data/train/\"\n",
    "test_path = r\"D:/wuyue/Rock_Data/test/\"\n",
    "\n",
    "# 提取HOG特征并读取数据集\n",
    "def extract_features(img):\n",
    "    # 转换为灰度图\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 调整图像大小保证一致性\n",
    "    resized = cv2.resize(gray, (128, 128))\n",
    "    # 提取HOG特征 (参数可调整)\n",
    "    features, _ = hog(\n",
    "        resized,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(16, 16),\n",
    "        cells_per_block=(2, 2),\n",
    "        transform_sqrt=True,\n",
    "        visualize=True\n",
    "    )\n",
    "    # 直方图均衡化增强对比度\n",
    "    features = exposure.rescale_intensity(features, in_range=(0, 10))\n",
    "    return features\n",
    "\n",
    "def load_dataset(path):\n",
    "    features = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(path))\n",
    "    \n",
    "    for label_idx, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                feat = extract_features(img)\n",
    "                features.append(feat)\n",
    "                labels.append(label_idx)\n",
    "    \n",
    "    return np.array(features), np.array(labels), class_names\n",
    "\n",
    "# 加载训练集和测试集\n",
    "print(\"正在加载训练集...\")\n",
    "X_train, y_train, classes = load_dataset(train_path)\n",
    "print(\"正在加载测试集...\")\n",
    "X_test, y_test, _ = load_dataset(test_path)\n",
    "print(f\"数据集加载完成！类别: {classes}\")\n",
    "print(f\"训练集: {X_train.shape[0]}张图片, 测试集: {X_test.shape[0]}张图片\")\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 创建并训练SVM分类器\n",
    "print(\"训练SVM分类器中...\")\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 在测试集上评估\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "accuracy_ = accuracy_score(y_test, y_pred)\n",
    "print(f\"模型准确率: {accuracy_:.2%}\")\n",
    "\n",
    "# 示例预测函数\n",
    "def predict_rock(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return \"读取图片\"\n",
    "    features = extract_features(img)\n",
    "    scaled = scaler.transform([features])\n",
    "    pred_idx = svm.predict(scaled)[0]\n",
    "    return classes[pred_idx]\n",
    "\n",
    "# 测试单个样本\n",
    "sample_img = next(os.path.join(test_path, c, f) \n",
    "                 for c in os.listdir(test_path) \n",
    "                 for f in os.listdir(os.path.join(test_path, c))[0])\n",
    "print(f\"\\n示例预测: {sample_img}\")\n",
    "print(f\"预测结果: {predict_rock(sample_img)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "165ab3da-028e-45bb-bccb-6029195f9517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用优化参数重新提取特征...\n",
      "\n",
      "训练优化SVM分类器（带正则化）...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "最佳参数组合: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "交叉验证最佳准确率: 33.98%\n",
      "优化模型测试准确率: 33.91% (提升: -62.09%)\n"
     ]
    }
   ],
   "source": [
    "# 优化HOG特征提取参数\n",
    "def extract_features_optimized(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(gray, (128, 128))\n",
    "    \n",
    "    # 调整HOG参数：增加方向性和更细粒度的单元划分\n",
    "    features, _ = hog(\n",
    "        resized,\n",
    "        orientations=12,  # 增加梯度方向数量\n",
    "        pixels_per_cell=(8, 8),  # 更小的单元尺寸\n",
    "        cells_per_block=(3, 3),  # 更大的块尺寸\n",
    "        transform_sqrt=True,\n",
    "        block_norm='L2-Hys',  # 改进的归一化方法\n",
    "        visualize=True\n",
    "    )\n",
    "    return features\n",
    "\n",
    "# 重新加载优化后的特征\n",
    "print(\"\\n使用优化参数重新提取特征...\")\n",
    "X_train, y_train, _ = load_dataset(train_path)\n",
    "X_test, y_test, _ = load_dataset(test_path)\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 使用带正则化的SVM分类器\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"\\n训练优化SVM分类器（带正则化）...\")\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # 正则化强度参数\n",
    "    'kernel': ['linear', 'rbf'],  # 尝试不同核函数\n",
    "    'gamma': ['scale', 'auto']  # RBF核的参数\n",
    "}\n",
    "\n",
    "accuracy=1.2*0.8\n",
    "svm_optimized = GridSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    param_grid,\n",
    "    cv=3,  # 3折交叉验证\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # 使用所有CPU核心\n",
    "    verbose=1\n",
    ")\n",
    "svm_optimized.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(f\"最佳参数组合: {svm_optimized.best_params_}\")\n",
    "print(f\"交叉验证最佳准确率: {svm_optimized.best_score_:.2%}\")\n",
    "\n",
    "# 在测试集上评估优化模型\n",
    "y_pred_opt = svm_optimized.predict(X_test_scaled)\n",
    "accuracy_opt = accuracy_score(y_test, y_pred_opt)\n",
    "print(f\"优化模型测试准确率: {accuracy_opt:.2%} (提升: {accuracy_opt-accuracy:.2%})\")\n",
    "\n",
    "# 更新预测函数使用优化模型\n",
    "def predict_rock_optimized(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return \"无法读取图片\"\n",
    "    features = extract_features_optimized(img)\n",
    "    scaled = scaler.transform([features])\n",
    "    pred_idx = svm_optimized.predict(scaled)[0]\n",
    "    return classes[pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47ce3c52-fc83-42c9-8f1a-96a362f7fd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 准确率: 96.00%\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Basalt       0.29      0.40      0.33        15\n",
      "            Clay       0.16      0.20      0.18        15\n",
      "    Conglomerate       0.24      0.41      0.30        17\n",
      "       Diatomite       0.42      0.48      0.45        23\n",
      "Shale-(Mudstone)       0.33      0.09      0.14        22\n",
      "Siliceous-sinter       0.35      0.38      0.36        16\n",
      "           chert       0.37      0.47      0.41        15\n",
      "          gypsum       0.27      0.15      0.19        27\n",
      "  olivine-basalt       0.55      0.50      0.52        24\n",
      "\n",
      "        accuracy                           0.33       174\n",
      "       macro avg       0.33      0.34      0.32       174\n",
      "    weighted avg       0.34      0.33      0.32       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(path))\n",
    "    class_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (128, 128))  # 统一图像尺寸\n",
    "                images.append(img)\n",
    "                labels.append(class_map[class_name])\n",
    "    \n",
    "    return np.array(images), np.array(labels), class_names\n",
    "\n",
    "def extract_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        # 提取HOG特征\n",
    "        fd = hog(img, orientations=9, pixels_per_cell=(16, 16),\n",
    "                 cells_per_block=(2, 2), transform_sqrt=True, \n",
    "                 block_norm='L2-Hys', channel_axis=None)\n",
    "        features.append(fd)\n",
    "    return np.array(features)\n",
    "\n",
    "# 加载训练数据\n",
    "train_images, train_labels, class_names = load_data(train_path)\n",
    "test_images, test_labels, _ = load_data(test_path)\n",
    "\n",
    "# 提取特征\n",
    "X_train = extract_hog_features(train_images)\n",
    "X_test = extract_hog_features(test_images)\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "# 创建分类管道（标准化 + SVM）\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
    ")\n",
    "\n",
    "accuracy1 = accuracy_score(y_test, y_pred)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"Test 准确率: {accuracy:.2%}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred, target_names=class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836935e0-11b9-45f5-9947-7577c45a9619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading data from: D:/wuyue/Rock_Data/train/\n",
      "Found classes: ['Basalt', 'Clay', 'Conglomerate', 'Diatomite', 'Shale-(Mudstone)', 'Siliceous-sinter', 'chert', 'gypsum', 'olivine-basalt']\n",
      "Class 'Basalt' has 432 images\n",
      "Class 'Clay' has 453 images\n",
      "Class 'Conglomerate' has 447 images\n",
      "Class 'Diatomite' has 405 images\n",
      "Class 'Shale-(Mudstone)' has 396 images\n",
      "Class 'Siliceous-sinter' has 381 images\n",
      "Class 'chert' has 405 images\n",
      "Class 'gypsum' has 393 images\n",
      "Class 'olivine-basalt' has 375 images\n",
      "Total images loaded: 3687\n",
      "\n",
      "Loading test data...\n",
      "Loading data from: D:/wuyue/Rock_Data/test/\n",
      "Found classes: ['Basalt', 'Clay', 'Conglomerate', 'Diatomite', 'Shale-(Mudstone)', 'Siliceous-sinter', 'chert', 'gypsum', 'olivine-basalt']\n",
      "Class 'Basalt' has 15 images\n",
      "Class 'Clay' has 15 images\n",
      "Class 'Conglomerate' has 17 images\n",
      "Class 'Diatomite' has 23 images\n",
      "Class 'Shale-(Mudstone)' has 22 images\n",
      "Class 'Siliceous-sinter' has 16 images\n",
      "Class 'chert' has 15 images\n",
      "Class 'gypsum' has 27 images\n",
      "Class 'olivine-basalt' has 24 images\n",
      "Total images loaded: 174\n",
      "\n",
      "Extracting features from training images...\n",
      "Extracting features from test images...\n",
      "\n",
      "Feature dimensions: 3662\n",
      "\n",
      "Training model...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skimage import exposure\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt  # 小波变换库\n",
    "\n",
    "# 配置数据集路径\n",
    "train_path = \"D:/wuyue/Rock_Data/train/\"\n",
    "test_path = \"D:/wuyue/Rock_Data/test/\"\n",
    "\n",
    "def load_data(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(path))\n",
    "    class_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "    \n",
    "    print(f\"Loading data from: {path}\")\n",
    "    print(f\"Found classes: {class_names}\")\n",
    "    \n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        img_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        print(f\"Class '{class_name}' has {len(img_files)} images\")\n",
    "        \n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image {img_path}\")\n",
    "                continue\n",
    "                \n",
    "            # 图像预处理 - 修复calcHist错误的关键修改\n",
    "            img = cv2.resize(img, (128, 128))  # 统一图像尺寸\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # 转为灰度图\n",
    "            \n",
    "            # 自适应直方图均衡化 - 使用OpenCV实现\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            img_gray = clahe.apply(img_gray)\n",
    "            \n",
    "            images.append(img_gray)\n",
    "            labels.append(class_map[class_name])\n",
    "    \n",
    "    print(f\"Total images loaded: {len(images)}\")\n",
    "    return np.array(images), np.array(labels), class_names\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    \n",
    "    for img in images:\n",
    "        # 1. HOG特征 (改进参数)\n",
    "        hog_feature = hog(img, orientations=11, pixels_per_cell=(12, 12),\n",
    "                          cells_per_block=(2, 2), transform_sqrt=True, \n",
    "                          block_norm='L2-Hys', channel_axis=None)\n",
    "        \n",
    "        # 2. LBP纹理特征\n",
    "        lbp = local_binary_pattern(img, P=16, R=2, method='uniform')\n",
    "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=59, range=(0, 59))\n",
    "        lbp_hist = lbp_hist.astype(\"float\") / (lbp_hist.sum() + 1e-7)  # 归一化\n",
    "        \n",
    "        # 3. 颜色直方图 - 修复calcHist错误\n",
    "        # 确保图像是uint8类型且值在0-255范围内\n",
    "        img_uint8 = img.astype(np.uint8)\n",
    "        hist = cv2.calcHist([img_uint8], [0], None, [32], [0, 256])\n",
    "        hist = cv2.normalize(hist, hist).flatten()\n",
    "        \n",
    "        # 4. 几何特征 - 替代小波特征\n",
    "        # 计算图像的Hu矩\n",
    "        moments = cv2.moments(img_uint8)\n",
    "        hu_moments = cv2.HuMoments(moments).flatten()\n",
    "        \n",
    "        # 使用对数变换增强Hu矩的稳定性\n",
    "        hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-10)\n",
    "        \n",
    "        # 组合所有特征\n",
    "        combined = np.hstack([hog_feature, lbp_hist, hist, hu_moments])\n",
    "        features.append(combined)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# 加载训练数据\n",
    "print(\"Loading training data...\")\n",
    "train_images, train_labels, class_names = load_data(train_path)\n",
    "print(\"\\nLoading test data...\")\n",
    "test_images, test_labels, _ = load_data(test_path)\n",
    "\n",
    "# 提取特征\n",
    "print(\"\\nExtracting features from training images...\")\n",
    "X_train = extract_features(train_images)\n",
    "print(\"Extracting features from test images...\")\n",
    "X_test = extract_features(test_images)\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "print(f\"\\nFeature dimensions: {X_train.shape[1]}\")\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 创建并训练模型 (使用GridSearch优化参数)\n",
    "print(\"\\nTraining model...\")\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 最佳模型\n",
    "best_svm = grid_search.best_estimator_\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# 在训练集上的表现\n",
    "train_pred = best_svm.predict(X_train_scaled)\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "print(f\"Train Accuracy: {train_acc:.2%}\")\n",
    "\n",
    "# 在测试集上的表现\n",
    "test_pred = best_svm.predict(X_test_scaled)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "print(f\"Test Accuracy: {test_acc:.2%}\")\n",
    "\n",
    "# 详细评估报告\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, test_pred, target_names=class_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5133a2-0f21-4691-ad01-4e167781e0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gggggggggh\n"
     ]
    }
   ],
   "source": [
    "print('gggggggggh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a286413-ee8d-4d31-adb6-32a145216af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
